alpha <- par$alpha
eta<-par$eta
v <- par$v
mg <- apply(unmap(ltrain),2,sum)
pig <- mg/m
factor1 <- 0
factor2 <- 0
factor3 <- 0 # Malahanobis distance
a <- rep(0,G)
b <- rep(0,G)
S <- rep(0,G)
eta1 <-  rep(0,G)
alpha1 <- rep(0,G)
mu1 <- matrix(0.0,nrow = p, ncol = G)
sigma1 <- array(0.0, dim = c(p,p,G))
W <- array(0.0, dim = c(p,p,G) )
output <- list()
# Calculate Sg, (r+1)th iteration Sg,mu1, alpha1, and (r-th) a
for(g in 1:G)
{
for(i in 1:m)
{
factor1 <-l[i,g]*(v[i,g] + (1-v[i,g])/eta[g] )
S[g] <- S[g] + factor1
mu1[,g] <- mu1[,g] + factor1 * Xtrain[i,]
alpha1[g] <- alpha1[g]+ (l[i,g]*v[i,g])
a[g] <- a[g] + l[i,g]*(1-v[i,g])
# equal covariance matrix
}#End-for
mu1[,g] <- mu1[,g]/S[g]
alpha1[g] <- alpha1[g]/mg[g]
}#End=for
# Calculate Wg and (r+1)th Sigma
for(g in 1:G)
{
for(i in 1:m)
{
factor2 <- l[i,g]*(v[i,g] + (1-v[i,g])/eta[g])
W[,,g] <- W[,,g] + factor2 * (Xtrain[i,]-mu1[,g])%*%t(Xtrain[i,]-mu1[,g])
}#End-for
# Calculating Sigma1
sigma1[,,g] <- W[,,g]/mg[g]
}#End-for
for (g in 1:G)
{
for( i in 1:m)
{
# factor 3: mahalanobis distance
factor3 <- mahalanobis(Xtrain[i,],mu1[,g],sigma1[,,g])
b[g] <- b[g] + l[i,g]*(1-v[i,g])*factor3
}
#    if(any(b[g] == 0))
#      eta1[g] <- 1.001
#    else  eta1[g]<-max(1.001,b[g]/(p*a[g]))
if(a[g]!=0)
{
eta1[g]<-max(1.001,b[g]/(p*a[g]))
}else eta1[g] <- 1
}
output <- list(mu = mu1, sigma = sigma1, eta = eta1,
v = v,alpha = alpha1, pig = pig, G = G)
return(output)
}
emCmn <-function(Xtrain,ltrain,par)
{
estep1<-eCmn(Xtrain,par)
par$v <- estep1$v
mstep1 <- mCmn(Xtrain,ltrain,par)
return(mstep1)
}
EMContMN <- function(X_train,l_train,CE)
{
if(length(dim(X_train)) == 2)
{
p <- ncol(X_train)
m <- nrow(X_train)
}
z <- unmap(l_train)
G <- ncol(z)
mg <- rep(0,G)
pig <- rep(0.0,G)
Sg <- rep(0.0,G)
etag <- rep(1.0, G)
bg <- rep(0.0,G)
mug <- matrix(0.0,ncol = p, nrow = G)
W <- array(0.0, dim = c( p, p,G))
weights <- matrix(0.0,ncol = G,nrow =m)
Sigmag <- array(0.0, dim = c(p,p,G) )
ag <- rep(0.0, G)
ng <- apply(z,2,sum)
pig <- ng/n
# Initialize v's
v <- matrix(runif(n*p),nrow = n, ncol = G)
v_1 <- rep(0.0, nrow = nrow(z), ncol = ncol(z))
v_2 <- rep(0.0, nrow = nrow(z), ncol = ncol(z))
stop = F
while(stop == F)
{
#  Updating r+1 mu_g
for (g in 1:G)
{
Sigmag[,,g] <- W[,,g]/ng[g]
}
for(g in 1:G)
{
# Sigma g (r+1)
c
for(i in 1:n)
{
weights[i,g] <- ( v[i,g] + ( 1-v[i,g] ) /etag[g] )
Sg[g] <- Sg[g] + z[i,g]* weights[i,g]
mug[g,] <- mug[g,] + ( z[i,g] *  weights[i,g]*X_train[i,] )
} # End-For
mug[g,] <-mug[g,]/Sg[g]
for(i in 1:n)
{
W[,,g] <- W[,,g]+ ( z[i,g] *  weights[i,g] ) * ( (X_train[i,]-mug[g,]) %*% t(X_train[i,]-mug[,g]) )
}# End-For
}
mug
Sg
W[,,1]
W[,,2]
}
}
nVarSel <- 0
GenData <- SimGClasses(mu,sg,pig,nobservations,ptraining,alphag,etag)
library(readxl)
library(skimr)
library(rgl)
install.packages("skimr")
install.packages("rgl")
library(skimr)
library(skimr)
library(rgl)
install.packages("shiny")
install.packages("shiny", dependencies = TRUE)
install.packages("shiny", dependencies = TRUE)
library(rgl)
library(rgl)
install.packages("rgl")
library(rgl)
install.packages("stringi")
install.packages("mclust")
install.packages("mclust")
### Power and Weight
workPath <- c("/home/jsancheg/git_environment/RegressionLab")
#Load the data
phys <- read.csv("phys1.csv")
setwd(workPath)
### Power and Weight
workPath <- c("/home/jsancheg/git_environment/RegressionLab")
setwd(workPath)
getwd()
### Power and Weight
workPath <- "/home/jsancheg/git_environment/RegressionLab"
setwd(workPath)
?setwd
### Power and Weight
workPath <- "./home/jsancheg/git_environment/RegressionLab"
getwd()
setwd(workPath)
### Power and Weight
workPath <- c("/home/jsancheg/git_environment/RegressionLab/")
getwd()
setwd(workPath)
setwd("~/git_environment/RegresionLab")
### Power and Weight
workPath <- c("~/git_environment/RegressionLab/")
getwd()
setwd(workPath)
#Load the data
phys <- read.csv("phys1.csv")
#Check column names
names(phys)
#View data
View(phys)
#Plot power1 against weight
plot(Power1 ~ Weight, data=phys)
#Add labels
plot(Power1 ~ Weight, data=phys, xlab="Weight (kgs)", ylab="Power Output (Watts)")
#Change size
plot(Power1 ~ Weight, data=phys, xlab="Weight (kgs)", ylab="Power Output (Watts)", cex=1.5)
#Change symbol
plot(Power1 ~ Weight, data=phys, xlab="Weight (kgs)", ylab="Power Output (Watts)", cex=1.5, pch=19)
#Change colour
plot(Power1 ~ Weight, data=phys, xlab="Weight (kgs)", ylab="Power Output (Watts)", cex=1.5, pch=19,col="blue")
#Use ggplot to plot
library(ggplot2) #you need to install this package if it does not load
#install.packages("ggplot2")
ggplot(data=phys, aes(y=Power1,x= Weight))+ #Specify x and y axes
geom_point(size = 3, color="blue") + #Specify to plot points size 2 coloured blue
labs(x="Weight (kgs)", y="Power Output (Watts)")+ #Specify axes labels
theme(text = element_text(size=20)) #Change size of axes labels
#Specify points to be coloured by gender.
ggplot(data=phys, aes(y=Power1,x= Weight,color=Gender)) +
geom_point(size = 3) +
labs(x="Weight (kgs)", y="Power Output (Watts)") +
theme(text = element_text(size=20))
#Estimate correlation between power1 and weight
cor(phys$Power1, phys$Weight)
#Test the null hypothesis that the population correlation coefficient is equal to zero
cor.test(phys$Power1, phys$Weight)
#Fit a simple linear regression
model1<-lm(Power1 ~ Weight, data=phys)
summary(model1)
#Fit a multiple linear regression adding gender
model2<-lm(Power1 ~ Weight + Gender, data=phys)
summary(model2)
#Try now including an interaction between weight and gender
model3<-lm(Power1 ~ Weight * Gender, data=phys)
summary(model3)
#Fit a simple linear regression
model1<-lm(Power1 ~ Weight, data=phys)
summary(model1)
#Test the null hypothesis that the population correlation coefficient is equal to zero
cor.test(phys$Power1, phys$Weight)
#Fit a simple linear regression
model1<-lm(Power1 ~ Weight, data=phys)
summary(model1)
#Fit a multiple linear regression adding gender
model2<-lm(Power1 ~ Weight + Gender, data=phys)
summary(model2)
#Try now including an interaction between weight and gender
model3<-lm(Power1 ~ Weight * Gender, data=phys)
summary(model3)
#Make plot with these two separate fitted lines included from model3
newdata<-data.frame(Weight=rep(seq(40,90,length=50),2), Gender=rep(c("Male","Female"),rep(50,2)) )
pred3<-predict(model3, newdata)
newdata1<-data.frame(newdata, pred=pred3)
#Specify points to be coloured by gender.
ggplot(data=phys, aes(y=Power1,x= Weight,color=Gender)) +
geom_point(size = 3) +
labs(x="Weight (kgs)", y="Power Output (Watts)") +
theme(text = element_text(size=20)) +
geom_line(aes(y=pred,x= Weight,color=Gender), data=newdata1,size=2)
#Make plot with these two separate fitted lines included from model2
newdata<-data.frame(Weight=rep(seq(40,90,length=50),2), Gender=rep(c("Male","Female"),rep(50,2)) )
pred2<-predict(model2, newdata)
newdata1<-data.frame(newdata, pred=pred2)
#Specify points to be coloured by gender.
ggplot(data=phys, aes(y=Power1,x= Weight,color=Gender)) +
geom_point(size = 3) +
labs(x="Weight (kgs)", y="Power Output (Watts)") +
theme(text = element_text(size=20)) +
geom_line(aes(y=pred,x= Weight,color=Gender), data=newdata1,size=2)
#Load data
hubble <- read.csv("hubble.csv")
#Check column names
names(hubble)
#View data
View(hubble)
#Plot velocity against disance
plot(Velocity~Distance, data=hubble, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Distance (megaparsecs)", ylab="Velocity (km/sec)")
#ggplot
ggplot(data=hubble, aes(y=Velocity,x=Distance))+
geom_point(size = 3, color="blue") +
labs(x="Distance (megaparsecs)", y="Velocity (km/sec)")+
theme(text = element_text(size=20))
#Fit a simple linear regression
model <- lm(Velocity ~ Distance, data=hubble)
summary(model)
#Add fitted line to plot
plot(Velocity~Distance, data=hubble, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Distance (megaparsecs)", ylab="Velocity (km/sec)")
abline(model,lwd=2)
#With ggplot
ggplot(data=hubble, aes(y=Velocity,x=Distance))+
geom_point(size = 3, color="blue") +
labs(x="Distance (megaparsecs)", y="Velocity (km/sec)")+
theme(text = element_text(size=20))+
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="black")
#Fit the same model with no intercept term
model2 <- lm(Velocity ~ Distance - 1, data=hubble)
summary(model2)
#Add fitted line
plot(Velocity~Distance, data=hubble, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Distance (megaparsecs)", ylab="Velocity (km/sec)")
abline(model,lwd=2)
abline(model2,lwd=2,lty=2)
#With ggplot
ggplot(data=hubble, aes(y=Velocity,x=Distance))+
geom_point(size = 3, color="blue") +
labs(x="Distance (megaparsecs)", y="Velocity (km/sec)")+
theme(text = element_text(size=20))+
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="black") +
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="red",formula=y~x-1)
#Load data
books <- read.csv("books.csv")
#Check column names
names(books)
#View data
View(books)
#Plot number of books published over time
plot(Number.of.Books~Year, data=books, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Year", ylab="Number of Books Published")
#ggplot
ggplot(data=books, aes(y=Number.of.Books,x=Year))+
geom_point(size = 3, color="blue") +
labs(x="Year", y="Number of Books Published")+
theme(text = element_text(size=20))
#Fit a simple linear regression
model0 <- lm(Number.of.Books~Year, data=books)
summary(model0)
#Add a quadratic term
model1 <- lm(Number.of.Books~poly(Year,2), data=books)
summary(model1)
model1 <- lm(Number.of.Books~Year+I(Year^2), data=books)
summary(model1)
model2 <- lm(Number.of.Books~poly(Year,2,raw=TRUE), data=books)
summary(model2)
#Add fitted line to plot
plot(Number.of.Books~Year, data=books, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Year", ylab="Number of Books Published")
abline(model0,lwd=2,lty=2)
abline(model1,lwd=2,lty=1)
#Add line from quadratic model
newdata<-data.frame(Year=0:145)
pred<-predict(model1, newdata)
newdata1<-data.frame(newdata, pred=pred)
lines(newdata1$Year,newdata1$pred,lwd=2)
#ggplot
ggplot(data=books, aes(y=Number.of.Books,x=Year))+
geom_point(size = 3, color="blue") +
labs(x="Year", y="Number of Books Published")+
theme(text = element_text(size=20))+
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="black") +
geom_line(aes(y=pred,x= Year), data=newdata1,size=2)
#Load data
books <- read.csv("books.csv")
#Check column names
names(books)
#View data
View(books)
#Plot number of books published over time
plot(Number.of.Books~Year, data=books, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Year", ylab="Number of Books Published")
#ggplot
ggplot(data=books, aes(y=Number.of.Books,x=Year))+
geom_point(size = 3, color="blue") +
labs(x="Year", y="Number of Books Published")+
theme(text = element_text(size=20))
#Fit a simple linear regression
model0 <- lm(Number.of.Books~Year, data=books)
summary(model0)
#Add a quadratic term
model1 <- lm(Number.of.Books~poly(Year,2), data=books)
summary(model1)
model1 <- lm(Number.of.Books~Year+I(Year^2), data=books)
summary(model1)
model2 <- lm(Number.of.Books~poly(Year,2,raw=TRUE), data=books)
#Plot velocity against disance
plot(Velocity~Distance, data=hubble, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Distance (megaparsecs)", ylab="Velocity (km/sec)")
#ggplot
ggplot(data=hubble, aes(y=Velocity,x=Distance))+
geom_point(size = 3, color="blue") +
labs(x="Distance (megaparsecs)", y="Velocity (km/sec)")+
theme(text = element_text(size=20))
#Fit a simple linear regression
model <- lm(Velocity ~ Distance, data=hubble)
summary(model)
#Add fitted line to plot
plot(Velocity~Distance, data=hubble, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Distance (megaparsecs)", ylab="Velocity (km/sec)")
#Fit the same model with no intercept term
model2 <- lm(Velocity ~ Distance - 1, data=hubble)
summary(model2)
#Add fitted line
plot(Velocity~Distance, data=hubble, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Distance (megaparsecs)", ylab="Velocity (km/sec)")
abline(model,lwd=2)
abline(model2,lwd=2,lty=2)
#With ggplot
ggplot(data=hubble, aes(y=Velocity,x=Distance))+
geom_point(size = 3, color="blue") +
labs(x="Distance (megaparsecs)", y="Velocity (km/sec)")+
theme(text = element_text(size=20))+
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="black") +
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="red",formula=y~x-1)
#Load data
books <- read.csv("books.csv")
#Check column names
names(books)
#View data
View(books)
#Plot number of books published over time
plot(Number.of.Books~Year, data=books, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Year", ylab="Number of Books Published")
#ggplot
ggplot(data=books, aes(y=Number.of.Books,x=Year))+
geom_point(size = 3, color="blue") +
labs(x="Year", y="Number of Books Published")+
theme(text = element_text(size=20))
#Fit a simple linear regression
model0 <- lm(Number.of.Books~Year, data=books)
summary(model0)
#Add a quadratic term
model1 <- lm(Number.of.Books~poly(Year,2), data=books)
summary(model1)
model1 <- lm(Number.of.Books~Year+I(Year^2), data=books)
summary(model1)
model2 <- lm(Number.of.Books~poly(Year,2,raw=TRUE), data=books)
summary(model2)
#Add fitted line to plot
plot(Number.of.Books~Year, data=books, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Year", ylab="Number of Books Published")
abline(model0,lwd=2,lty=2)
abline(model1,lwd=2,lty=1)
#Add line from quadratic model
newdata<-data.frame(Year=0:145)
pred<-predict(model1, newdata)
newdata1<-data.frame(newdata, pred=pred)
lines(newdata1$Year,newdata1$pred,lwd=2)
#ggplot
ggplot(data=books, aes(y=Number.of.Books,x=Year))+
geom_point(size = 3, color="blue") +
labs(x="Year", y="Number of Books Published")+
theme(text = element_text(size=20))+
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="black") +
geom_line(aes(y=pred,x= Year), data=newdata1,size=2)
#Load data
cheese <- read.csv("cheese.csv")
#Check column names
names(cheese)
#View data
View(cheese)
attach(cheese)
#Plot taste against Acetic Acid
plot(Acetic.Acid,Taste, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Acetic Acid", ylab="Taste")
#ggplot
ggplot(data=cheese, aes(y=Taste,x=Acetic.Acid))+
geom_point(size = 3, color="blue") +
labs(x="Taste", y="Acetic Acid")+
theme(text = element_text(size=20))
#Plot taste against H2S
plot(H2S, Taste, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="H2S", ylab="Taste")
#ggplot
ggplot(data=cheese, aes(y=Taste,x=H2S))+
geom_point(size = 3, color="blue") +
labs(x="Taste", y="H2S")+
theme(text = element_text(size=20))
#Plot taste against Lactic Acid
plot(Lactic.Acid, Taste, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Lactic Acid", ylab="Taste")
#ggplot
ggplot(data=cheese, aes(y=Taste,x=Lactic.Acid))+
geom_point(size = 3, color="blue") +
labs(x="Taste", y="Lactic Acid")+
theme(text = element_text(size=20))
#Fit a simple linear regression
model <- lm(Taste~Lactic.Acid, data=cheese)
summary(model)
#Plot taste against Lactic Acid with fitted line
plot(Lactic.Acid, Taste, cex=1.5, col="blue", pch=19, cex.lab=1.5,
xlab="Lactic Acid", ylab="Taste")
abline(model,lwd=2)
#ggplot
ggplot(data=cheese, aes(y=Taste,x=Lactic.Acid))+
geom_point(size = 3, color="blue") +
labs(x="Taste", y="Lactic Acid")+
theme(text = element_text(size=20)) +
geom_smooth(method="lm", fill=NA, fullrange=TRUE,color="black")
#Correlation between taste and lactic acid
cor.test(cheese$Taste,cheese$Lactic.Acid)
##Load data
data <- read.csv("AGESf.csv")
##First need to format the data
Age<-rep(data$Age,3)
Guess<-c(data[,2],data[,3],data[,4])
Class<-as.factor(rep(19:21,rep(13,3)))
df<-data.frame(Age=Age,Guess=Guess,Class=Class)
head(df)
### Plot these data
ggplot(data=df, aes(x=Guess,y=Age, colour =Class, shape=Class))+
geom_point(size = 5, alpha = 0.75)+
theme(plot.margin = margin(0,0,0,0, "cm"),
plot.background = element_rect(
fill = "transparent",
colour = NA,
size = 1))
### Fit additive model with Guess and Class
model2<-lm(Age~Guess+Class,data=df)
### Fit additive model with Guess and Class
model2<-lm(Age~Guess+Class,data=df)
round(summary(model2)$coefficients,2)
### Plot these data
ggplot(data=df, aes(x=Guess,y=Age, colour =Class, shape=Class))+
geom_point(size = 5, alpha = 0.75) +
theme(plot.margin = margin(0,0,0,0, "cm"),
plot.background =
element_rect(fill = "transparent",colour = NA,size = 1)) +
geom_abline(intercept=7.09, slope=1.12, color="red") +
geom_abline(intercept=7.0-19.679, slope=1.12, color="green") +
geom_abline(intercept=7.09+0.47, slope=1.12, color="blue")
###Repeat the above steps with an interaction between Class and Guess
model3<-lm(Age~Guess*Class,data=df)
round(summary(model3)$coefficients,2)
### Plot these data
ggplot(data=df, aes(x=Guess,y=Age, colour =Class, shape=Class))+
geom_point(size = 5, alpha = 0.75) +
theme(plot.margin = margin(0,0,0,0, "cm"),
plot.background =
element_rect(fill = "transparent",colour = NA,size = 1)) +
geom_abline(intercept=6.08, slope=1.14, color="red") +
geom_abline(intercept=6.08-16.67, slope=1.14-0.06, color="green") +
geom_abline(intercept=6.08+1.15, slope=1.14-0.02, color="blue")
### Based on the fitted line plots, which model do you prefer?
### Based on the fitted line plots, which model do you prefer?
